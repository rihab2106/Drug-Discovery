{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\rdenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from argparse import ArgumentParser\n",
    "\n",
    "import torch\n",
    "import sklearn\n",
    "import torch.nn as nn\n",
    "\n",
    "from utils import init_featurizer, mkdir_p, get_configure, load_model, load_dataloader, predict\n",
    "from get_edit import write_edits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test(args):\n",
    "    model_name = 'LocalRetro_%s.pth' % args['dataset']\n",
    "    args['model_path'] = '../models/%s' % model_name\n",
    "    args['config_path'] = '../data/configs/%s' % args['config']\n",
    "    args['data_dir'] = '../data/%s' % args['dataset']\n",
    "    args['result_path'] = '../outputs/raw_prediction/%s' % model_name.replace('.pth', '.txt')\n",
    "    mkdir_p('../outputs')\n",
    "    mkdir_p('../outputs/raw_prediction')\n",
    "    \n",
    "    args = init_featurizer(args)\n",
    "    model = load_model(args)\n",
    "    test_loader = load_dataloader(args)\n",
    "    write_edits(args, model, test_loader)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory ../outputs already exists.\n",
      "Directory ../outputs/raw_prediction already exists.\n",
      "Parameters of loaded LocalRetro:\n",
      "{'attention_heads': 8, 'attention_layers': 1, 'batch_size': 16, 'edge_hidden_feats': 64, 'node_out_feats': 320, 'num_step_message_passing': 6, 'AtomTemplate_n': 43, 'BondTemplate_n': 194, 'in_node_feats': 80, 'in_edge_feats': 13}\n",
      "Loading previously saved test dgl graphs...\n",
      "Writing test molecule batch 12/13\n"
     ]
    }
   ],
   "source": [
    "default_args = {\n",
    "    'gpu': 'cuda:0',\n",
    "    'dataset': 'USPTO_50K_data',\n",
    "    'config': 'default_config.json',\n",
    "    'batch_size': 16,\n",
    "    'top_num': 100,\n",
    "    'num_workers': 0,\n",
    "    'mode': 'test',\n",
    "    'device': torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "}\n",
    "test(default_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\rdenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os, sys, re\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "from collections import defaultdict\n",
    "from argparse import ArgumentParser\n",
    "sys.path.append('../')\n",
    "    \n",
    "import rdkit\n",
    "from rdkit import Chem, RDLogger \n",
    "from rdkit.Chem import rdChemReactions\n",
    "\n",
    "from utils import mkdir_p\n",
    "from LocalTemplate.template_decoder import *\n",
    "\n",
    "def get_k_predictions(test_id, args):\n",
    "    raw_prediction = args['raw_predictions'][test_id]\n",
    "    all_prediction = []\n",
    "    class_prediction = []\n",
    "    product = raw_prediction[0]\n",
    "    predictions = raw_prediction[1:]\n",
    "    for prediction in predictions:\n",
    "        mol, pred_site, template, template_info, score = read_prediction(product, prediction, args['atom_templates'], args['bond_templates'], args['template_infos'])\n",
    "        local_template = '>>'.join(['(%s)' % smarts for smarts in template.split('_')[0].split('>>')])\n",
    "        decoded_smiles = decode_localtemplate(mol, pred_site, local_template, template_info)\n",
    "        try:\n",
    "            decoded_smiles = decode_localtemplate(mol, pred_site, local_template, template_info)\n",
    "            if decoded_smiles == None or str((decoded_smiles, score)) in all_prediction:\n",
    "                continue\n",
    "        except Exception as e:\n",
    "#                     print (e)\n",
    "            continue\n",
    "        all_prediction.append(str((decoded_smiles, score)))\n",
    "\n",
    "        if args['rxn_class_given']:\n",
    "            rxn_class = args['test_rxn_class'][test_id]\n",
    "            if template in args['templates_class'][str(rxn_class)].values:\n",
    "                class_prediction.append(str((decoded_smiles, score)))\n",
    "            if len (class_prediction) >= args['top_k']:\n",
    "                break\n",
    "\n",
    "        elif len (all_prediction) >= args['top_k']:\n",
    "            break\n",
    "    return (test_id, (all_prediction, class_prediction))\n",
    "\n",
    "def decode_prediction(args):   \n",
    "    atom_templates = pd.read_csv('../data/%s/atom_templates.csv' % args['dataset'])\n",
    "    bond_templates = pd.read_csv('../data/%s/bond_templates.csv' % args['dataset'])\n",
    "    template_infos = pd.read_csv('../data/%s/template_infos.csv' % args['dataset'])\n",
    "    class_test = '../data/%s/class_test.csv' % args['dataset']\n",
    "    if os.path.exists(class_test):\n",
    "        args['rxn_class_given'] = True\n",
    "        args['templates_class'] = pd.read_csv('../data/%s/template_rxnclass.csv' % args['dataset'])\n",
    "        args['test_rxn_class'] = pd.read_csv(class_test)['class']\n",
    "    else:\n",
    "        args['rxn_class_given'] = False \n",
    "    args['atom_templates'] = {atom_templates['Class'][i]: atom_templates['Template'][i] for i in atom_templates.index}\n",
    "    args['bond_templates'] = {bond_templates['Class'][i]: bond_templates['Template'][i] for i in bond_templates.index}\n",
    "    args['template_infos'] = {template_infos['Template'][i]: {'edit_site': eval(template_infos['edit_site'][i]), 'change_H': eval(template_infos['change_H'][i]), 'change_C': eval(template_infos['change_C'][i]), 'change_S': eval(template_infos['change_S'][i])} for i in template_infos.index}\n",
    "    \n",
    "   \n",
    "    if args['model'] == 'default':\n",
    "        result_name = 'LocalRetro_%s.txt' % args['dataset']\n",
    "    else:\n",
    "        result_name = 'LocalRetro_%s.txt' % args['model']\n",
    "    \n",
    "    prediction_file =  '../outputs/raw_prediction/' + result_name\n",
    "    raw_predictions = {}\n",
    "    with open(prediction_file, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            seps = line.split('\\t')\n",
    "            if seps[0] == 'Test_id':\n",
    "                continue\n",
    "            raw_predictions[int(seps[0])] = seps[1:]\n",
    "        \n",
    "    output_path = '../outputs/decoded_prediction/' + result_name\n",
    "    output_path_class = '../outputs/decoded_prediction_class/' + result_name\n",
    "    args['raw_predictions'] = raw_predictions\n",
    "    # multi_processing\n",
    "    result_dict = {}\n",
    "    partial_func = partial(get_k_predictions, args = args)\n",
    "    with multiprocessing.Pool(processes=8) as pool:\n",
    "        tasks = range(len(raw_predictions))\n",
    "        for result in tqdm(pool.imap_unordered(partial_func, tasks), total=len(tasks), desc='Decoding LocalRetro predictions'):\n",
    "            result_dict[result[0]] = result[1]\n",
    "    \n",
    "        \n",
    "    with open(output_path, 'w') as f1, open(output_path_class, 'w') as f2:\n",
    "        for i in sorted(result_dict.keys()) :\n",
    "            all_prediction, class_prediction = result_dict[i]\n",
    "            f1.write('\\t'.join([str(i)] + all_prediction) + '\\n')\n",
    "            f2.write('\\t'.join([str(i)] + class_prediction) + '\\n')\n",
    "            print('\\rDecoding LocalRetro predictions %d/%d' % (i, len(raw_predictions)), end='', flush=True)\n",
    "    print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'decode_prediction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2848\\1565861334.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m               \"top_k\": 50}\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdecode_prediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'decode_prediction' is not defined"
     ]
    }
   ],
   "source": [
    "default_args={\"dataset\": \"USPTO_50K_data\",\n",
    "              \"model\": \"default\",\n",
    "              \"top_k\": 50}\n",
    "\n",
    "decode_prediction(default_args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rdenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
